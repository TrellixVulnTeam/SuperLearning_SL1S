{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3: Working with Pandas\n",
    "\n",
    "Welcome back! Last week we started doing some real data analysis, but we were writing extremely basic functionality by hand. While it's important to be familiar with the language and understand how things like that work, in practice you wouldn't want to have to reimplement a mean-finding function from scratch every time you're starting a new data analysis project.\n",
    "\n",
    "Enter [Pandas](http://pandas.pydata.org/), the Python Data Analysis library. Pandas is one of the newer additions to the scientific Python ecosystem, but it's already a mature and very powerful tool. If you've worked with R before, or other statistical software, many of the concepts will be familiar to you. Pandas introduces Series (indexed lists) and DataFrames (data organized table-style into rows and columns), and provides a range of functionality built in. So let's get started!\n",
    "\n",
    "The first thing we do is import the pandas module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "\n",
    "The basic pandas object is a Series. We can create a series from a list, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 3, 5, 7, 9, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the series contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     3\n",
       "2     5\n",
       "3     7\n",
       "4     9\n",
       "5    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the two columns above; the first, leftmost column is the index, which is just the same 0 to 5 values you'd expect in a regular list. The righthand column is the actual values the series is storing.\n",
    "\n",
    "The Series object comes built-in with quite a few basic functions. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the Series is 36.000000.\n",
      "The mean of the Series is 6.000000.\n",
      "The median of the Series is 6.000000.\n"
     ]
    }
   ],
   "source": [
    "print(\"The sum of the Series is %f.\" % s.sum())\n",
    "print(\"The mean of the Series is %f.\" % s.mean())\n",
    "print(\"The median of the Series is %f.\" % s.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform artithmetic operations on a series; the operation will be done element by element, and the result will be another series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1     4\n",
       "2     6\n",
       "3     8\n",
       "4    10\n",
       "5    12\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the result is a new series, we can assign it to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1     6\n",
      "2    10\n",
      "3    14\n",
      "4    18\n",
      "5    22\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "double_s = s * 2\n",
    "print(double_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform arithmetic *between* series; the results will again be another series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.Series([1, 2, 3])\n",
    "b = pd.Series([2, 4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3\n",
       "1     6\n",
       "2    11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1   -2\n",
       "2   -5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2\n",
       "1     8\n",
       "2    24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.500\n",
       "1    0.500\n",
       "2    0.375\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate over series in much the same way as lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "3 9\n",
      "5 25\n",
      "7 49\n",
      "9 81\n",
      "11 121\n"
     ]
    }
   ],
   "source": [
    "for x in s:\n",
    "    print(x, x*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use list comprehension, though it gives us a list, not a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 9, 25, 49, 81, 121]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x*x for x in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of this position within my_list is 1.\n",
      "The value of this position within my_list is 9.\n",
      "The value of this position within my_list is 25.\n",
      "The value of this position within my_list is 49.\n",
      "The value of this position within my_list is 81.\n",
      "The value of this position within my_list is 121.\n"
     ]
    }
   ],
   "source": [
    "my_list = [x*x for x in s]\n",
    "for i in my_list:\n",
    "    print(\"The value of this position within my_list is %d.\" % i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a series with the square of values, plus some added random 'noise'.\n",
    "\n",
    "#### Sidebar: generating random numbers:\n",
    "\n",
    "To get the noise, we'll use the built-in **random** module, which provides several random number generators. The most basic one, also called **random()**, simply picks a random number with uniform probability from the interval [0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The added random noise is 0.736648\n"
     ]
    }
   ],
   "source": [
    "print(\"The added random noise is %f\" % random.random()) # Your results will obviously be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also draw a number from a [normal (Gaussian) distribution](http://en.wikipedia.org/wiki/Normal_distribution), with specified mean and standard deviations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The random noise from a normal(Gaussian) distribution is -0.824124.\n"
     ]
    }
   ],
   "source": [
    "print(\"The random noise from a normal(Gaussian) distribution is %f.\" \n",
    "      % random.normalvariate(0, 1)) # Mean 0 and standard deviation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### End sidebar\n",
    "\n",
    "So, let's square the original series and add some random noise; we can use list comprehension, and turn the resulting list immediately into a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3.273568\n",
       "1      8.617122\n",
       "2     25.442064\n",
       "3     49.981854\n",
       "4     81.656800\n",
       "5    121.182118\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2 = pd.Series([x*x + random.normalvariate(0, 1) for x in s])\n",
    "s2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series\n",
    "\n",
    "Pandas was originally designed with financial analysis in mind, so it's no surprise that it has great time series functionality. Instead of just using the default 0, 1, 2... indices, we can index a Series on anything we want -- including datetime objects. \n",
    "\n",
    "First, we import the datetime module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want a monthly time-series. We first need to create a list of datetime objects representing the beginning of every month, to use as our index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [dt.datetime(2001, x, 1) for x in range(1,13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2001, 1, 1, 0, 0),\n",
       " datetime.datetime(2001, 2, 1, 0, 0),\n",
       " datetime.datetime(2001, 3, 1, 0, 0),\n",
       " datetime.datetime(2001, 4, 1, 0, 0),\n",
       " datetime.datetime(2001, 5, 1, 0, 0),\n",
       " datetime.datetime(2001, 6, 1, 0, 0),\n",
       " datetime.datetime(2001, 7, 1, 0, 0),\n",
       " datetime.datetime(2001, 8, 1, 0, 0),\n",
       " datetime.datetime(2001, 9, 1, 0, 0),\n",
       " datetime.datetime(2001, 10, 1, 0, 0),\n",
       " datetime.datetime(2001, 11, 1, 0, 0),\n",
       " datetime.datetime(2001, 12, 1, 0, 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to create a series with a custom index is with a dictionary: keys are the index, and values are the values. Here, we create a dictionary associating each of the datetimes with a random value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = {}\n",
    "for date in months:\n",
    "    time_series[date] = random.normalvariate(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2001, 1, 1, 0, 0): -0.908522903887484,\n",
       " datetime.datetime(2001, 2, 1, 0, 0): -1.4727208534585645,\n",
       " datetime.datetime(2001, 3, 1, 0, 0): 1.2535327866433175,\n",
       " datetime.datetime(2001, 4, 1, 0, 0): 0.5387039358343666,\n",
       " datetime.datetime(2001, 5, 1, 0, 0): -0.6687544351996593,\n",
       " datetime.datetime(2001, 6, 1, 0, 0): 0.9347784538597698,\n",
       " datetime.datetime(2001, 7, 1, 0, 0): 0.6021362426932529,\n",
       " datetime.datetime(2001, 8, 1, 0, 0): 0.02042778976170365,\n",
       " datetime.datetime(2001, 9, 1, 0, 0): -2.3426337348547985,\n",
       " datetime.datetime(2001, 10, 1, 0, 0): -1.6518215780106638,\n",
       " datetime.datetime(2001, 11, 1, 0, 0): -0.2795573309327898,\n",
       " datetime.datetime(2001, 12, 1, 0, 0): 1.4831521436420247}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lesser-known Python trick is that just like list comprehension, there is also dictionary comprehension: creating a dictionary from a known set of keys. We can simplify the above code like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.datetime(2001, 1, 1, 0, 0): 0.17706493213324254,\n",
       " datetime.datetime(2001, 2, 1, 0, 0): -0.21459099022197228,\n",
       " datetime.datetime(2001, 3, 1, 0, 0): 0.4681321258107382,\n",
       " datetime.datetime(2001, 4, 1, 0, 0): -0.6696929940286754,\n",
       " datetime.datetime(2001, 5, 1, 0, 0): 0.7954593895249394,\n",
       " datetime.datetime(2001, 6, 1, 0, 0): -0.6359387277383811,\n",
       " datetime.datetime(2001, 7, 1, 0, 0): 0.40280077031876327,\n",
       " datetime.datetime(2001, 8, 1, 0, 0): 0.5268754389056332,\n",
       " datetime.datetime(2001, 9, 1, 0, 0): 0.05177994717564795,\n",
       " datetime.datetime(2001, 10, 1, 0, 0): -0.02648044317175892,\n",
       " datetime.datetime(2001, 11, 1, 0, 0): -0.8422738046740902,\n",
       " datetime.datetime(2001, 12, 1, 0, 0): -0.9491526420948785}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series = {date: random.normalvariate(0,1) for date in months}\n",
    "time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dictionary associating dates with values, we can turn it into a pandas series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = pd.Series(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-01-01    0.177065\n",
       "2001-02-01   -0.214591\n",
       "2001-03-01    0.468132\n",
       "2001-04-01   -0.669693\n",
       "2001-05-01    0.795459\n",
       "2001-06-01   -0.635939\n",
       "2001-07-01    0.402801\n",
       "2001-08-01    0.526875\n",
       "2001-09-01    0.051780\n",
       "2001-10-01   -0.026480\n",
       "2001-11-01   -0.842274\n",
       "2001-12-01   -0.949153\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another useful bit of series functionality, that's especually handy for time series. The *cumsum()* function returns a new series, where each value is the cumulative sum of all the previous values. If we wanted to turn our random numbers into a random walk, we could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_total = time_series.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-01-01    0.177065\n",
       "2001-02-01   -0.037526\n",
       "2001-03-01    0.430606\n",
       "2001-04-01   -0.239087\n",
       "2001-05-01    0.556372\n",
       "2001-06-01   -0.079566\n",
       "2001-07-01    0.323235\n",
       "2001-08-01    0.850110\n",
       "2001-09-01    0.901890\n",
       "2001-10-01    0.875409\n",
       "2001-11-01    0.033136\n",
       "2001-12-01   -0.916017\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using the IPython Notebook, pandas can create a quick chart of the time series. If you're not using the Notebook, don't worry about it right now -- we'll go deeper into visualization (including how to do it from IDLE or the command line) next week.\n",
    "\n",
    "If you're in the IPython notebook, use the following command to prepare for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use the pandas series' built-in *plot()* method to create the chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9a36390>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEHCAYAAACqbOGYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl81PWd+PHXOzcJOQiTCxIgkAABQcQIVYKKRFHbihdWbLfa2rWX22273V273Z/tdteurbvbU7e19nBr662VthYURAURERAh4QzhCpCDBBKO3Hn//phvcBJzz2SuvJ+PRx6Z+R7zeU8yM+/5fk5RVYwxxphOEYEOwBhjTHCxxGCMMaYLSwzGGGO6sMRgjDGmC0sMxhhjurDEYIwxpgtLDMYYY7qwxGCMMaYLSwzGGGO6iAp0AEPhcrl00qRJgQ7DGGNCypYtW06oalp/x4VkYpg0aRKbN28OdBjGGBNSROTQQI6zqiRjjDFdWGIwxhjThSUGY4wxXVhiMMYY04UlBmOMMV1YYjDGGNOFJQZjzLDp6FBqzzTT3mErRYaSkBzHYIwJPqpKxclGdhytZ3tFPdsrTrHjaD2nm9qIEEhLjCUzKY70pDgyk+LITI4jPTGWzOS489uT4qIQkUA/lRHPEoMxZtBUlcqGJrZX1LOjop7tR+vZUXGKk+daAYiOFAqykrjhwnHkuhKob2ylsr6JyoYmDteeY9OBOuobWz/0uKOiI8lIiiXDSRwZSe6fzKS489vTk2KJjYr091MeUSwxGGP6VX26yZ0AKurPXxGcONMMQGSEMDUjkSUzM5mVnczs8SlMzRzd74d3U2s7VQ1NVNY3UXW6mSoncVQ5P1sPn6SqoZmWto4PnZuaEOMkjVgnaTgJJDmWC8Ynk54YNyx/h5HCEoMxpou6sy3scK4AOhPB8fomACIE8tJHc8XUNGZnJzMrO5kZWUnERQ/+G3xcdCQTxyYwcWxCr8eoKqfOtXZJGFUNze779U1UnW6i5GgDtWebUacZY2rGaF752hVDeu7GzRKDMSNYfWMrJUc7rwTciaDiZOP5/ZPTEpifm8qs7BRmO0kgIdZ/HxsiwpiEGMYkxFCQldTrca3tHdScbuapTYf5yWtllNecYXLaaL/FGW4sMRgzwry07Sird1Wzo+IUB2vPnd8+ITWeOTkpfPrSicwan8LM8UkkxUUHMNKBi46MYFzKKG67JIefvFbGml3Vlhi8YInBmBHkvcMn+funtpGZFMecnBSWFea4q4TGJ5MSHxPo8LyWPSae6ZmJrN5Vxd9ePjnQ4YQsSwzGjCAPry0jJT6aNf9whV+rhPypuCCD/31jP6fOtYRFsgsEG+BmzAhReqye1buquXtBbtgmBYDFBem0dyiv76kJdCghyxKDMSPEI2v3kxgbxacvmxToUIbVhdkpuEbHsnpXVaBDCVmWGIwZAcqqz/ByyXE+fdlEkkeFRoPyUEVECIunp/PG3poex0CY/lliMGYEeOT1MuKiIvnsgtxAh+IXiwvSOd3UxrsH6wIdSkiyxGBMmDtce46Xth3jk/MnMHZ0bKDD8YuifBexURFWnTRElhiMCXM/f3M/kSIjqvtmfEwUC/JcrN5VharN7DpYPkkMInKtiOwRkTIRua+H/T8UkW3Oz14ROeWxr91j3wpfxGOMcTte38hzmyu47ZJsMpJG1vxBiwvSOVLXyL7qM4EOJeR4nRhEJBJ4GLgOmAEsF5EZnseo6tdUdY6qzgF+Crzgsbuxc5+q3uBtPMaYDzz6Zjntqnz+8imBDsXvFk/PALDqpCHwxRXDPKBMVctVtQV4Cljax/HLgSd9UK4xpg8nzjTz5KbD3HTReHJS4wMdjt9lJscxa3wya3ZVBzqUkOOLxDAeOOJxv8LZ9iEiMhHIBV7z2BwnIptFZKOI3NhbISJyj3Pc5poaG7hiTH9+tf4AzW0dfOnKkXe10GlxQTpbD588P0W4GRhfJIaellvqrbXnduA5VW332DZBVQuBO4AfiUiPr2JVfVRVC1W1MC0tzbuIjQlz9eda+d3bh/jorKwRPZlccUEGqrB2t101DIYvEkMFkONxPxs41suxt9OtGklVjzm/y4HXgYt8EJMxI9pvNxzkTHMbX16UF+hQAmrmuCSykuOsOmmQfJEY3gXyRSRXRGJwf/h/qHeRiEwDxgBve2wbIyKxzm0XsADY6YOYjBmxzjS38eu3DnD1jIw+1zAYCUSEq6an8+a+Gppa2/s/wQA+SAyq2gbcC6wCdgHPqGqpiHxXRDx7GS0HntKunYoLgM0i8j6wFnhQVS0xGOOFJzYeor6xlXtH+NVCp+IZGZxraWdjeW2gQwkZPpliUVVfBl7utu3+bve/08N5G4BZvojBGONeR/mxdeUszHdxYU5KoMMJCpdOHkt8TCRrdlVz5bT0QIcTEmzkszFh5KlNhzlxpoW/uyo/0KEEjbjoSIryXKyxUdADZonBmDDR0tbBL94sZ96kVOblpgY6nKBSPCODY/VN7DzeEOhQQoIlBmPCxAtbKzhe38S9V1nbQndXTU9HBOudNECWGIwJA23tHTzy+n5mZyezMN8V6HCCjmt0LHNyUmx6jAGyxGBMGPjz9uMcrjvHvYvyEOlpzKkpLshge0U9VQ1NgQ4l6FliMCbEdXQoP1tbxvTMRIoLMgIdTtDq/Nu8ZqOg+2WJwZgQt6q0krLqM3xpUR4REXa10JupGaPJHjOK1TutOqk/lhiMCWGq7quFXFcCH52VFehwgpqIUFyQwfqyEzS22CjovlhiMCaEvb6nhtJjDXzpyilE2tVCv4oLMmhu6+CtshOBDiWoWWIwJkSpKj99bR/jU0Zx40U9znRvupmXm0pibJT1TuqHJQZjQtTb5bVsPXyKL1w5hehIeysPRExUBJdPS2PN7mo6OmwUdG/s1WRMiPrZa2WkJ8ay7OLsQIcSUooL0qk53cyOo/WBDiVoWWIwJgRtOXSSDftruefyycRFRwY6nJBy5dR0IsTWgu6LJQZjQtDDa8sYEx/NHfMnBDqUkDMmIYbCSamstukxemWJwYSEZ949wtFTjYEOIyiUHK3ntd3V3F2US3yMT2bOH3GKC9LZdbzBXlO9sMRggl5Z9Wn+6fnt/GDl7kCHEhQeXltGYlwUn75sUqBDCVmLnVHQa6w6qUeWGEzQW1lSCcBfd1Ry8mxLgKMJrH1Vp1lZWsldl00iKS460OGErClpo5nsSrDqpF5YYjBBb2VpJVnJcbS0d/D81opAhxNQj7y+n7ioSD6zIDfQoYS8xQXpbNxfy5nmtkCHEnR8khhE5FoR2SMiZSJyXw/77xKRGhHZ5vx8zmPfnSKyz/m50xfxmPBRcfIcJUcbuOuyScydkMIfNh0esatwHao9y0vbjvKpj0wgNSEm0OGEvMUFGbS0d7Bub02gQwk6XicGEYkEHgauA2YAy0VkRg+HPq2qc5yfx5xzU4FvA/OBecC3RWSMtzGZ8LGq1F0HvGRmJsvnTaC85iybDtQFOKrA+Pkb+4mKjOBvF04OdChhoXDiGJJHRVt1Ug98ccUwDyhT1XJVbQGeApYO8NwlwKuqWqeqJ4FXgWt9EJMJE6tKKpmemcgkVwIfmz2OxLgo/rDpcKDD8rtjpxp5bksFnyjMIT0pLtDhhIWoyAgWTUtj7Z5q2m0UdBe+SAzjgSMe9yucbd3dIiLbReQ5EckZ5LmIyD0isllENtfU2KXfSFBzupl3D9Vx7QWZAIyKieTmi8aPyEboR98sRxU+f4VdLfjS4oIM6s628N7hk4EOJaj4IjH0NKVj9/T7J2CSqs4GVgOPD+Jc90bVR1W1UFUL09LShhysCR2v7qxClfOJAWD5/AkjrhG65nQzT246zM1zx5M9Jj7Q4YSVK6alERUhVp3UjS8SQwWQ43E/GzjmeYCq1qpqs3P3l8DFAz3XjFwrSyuZNDaeaRmJ57dNz0wacY3Qj60vp7W9gy9emRfoUMJOUlw08yen2niGbnyRGN4F8kUkV0RigNuBFZ4HiIjnCiI3ALuc26uAa0RkjNPofI2zzYxw9Y2tbCg7wZKZmR9aw/iO+RMprznLOyOgEfrUuRaeePsQH5s9jlxXQqDDCUuLp2ewr/oMh2rPBjqUoOF1YlDVNuBe3B/ou4BnVLVURL4rIjc4h31FREpF5H3gK8Bdzrl1wL/jTi7vAt91tpkR7rXdVbR1KEs8qpE6fXRWFolxUTw5Ahqhf/PWQc62tPPlRXa1MFw614K26qQP+GQcg6q+rKpTVXWKqj7gbLtfVVc4t7+pqjNV9UJVXaSquz3O/bWq5jk/v/FFPCb0rSypJCMpljnZKR/aN1IaoU83tfKbtw5wzYwMpmUm9n+CGZIJY+OZmjHaqpM82MhnE3QaW9p5Y28NS2Zm9rq4/UhohH5i42Eamtq49yq7Whhuiwsy2HSgjvrG1kCHEhQsMYSJLYdOcvujb4fFC/uNvTU0tXZw7cwPVyN1CvdG6MaWdh5bV87lU9OY3cNVk/Gt4oIM2jqUN2wUNGCJISx0dCj3v1TCxvI6Vmw7GuhwvLaqtJKU+Gjm5ab2eVw4N0I/uekwtWdb+Du7WvCLOTkpjE2IYfVOq04CSwxh4U/bj1F6rIFR0ZE8szm0q1Za2jpYvauKqwsyiOpnHeNwbYRubmvn0TfLmZ+byiWT+k6OxjciI4RF09N5fU81re0dgQ4n4CwxhLjmtnYeWrWHGVlJfGPJNHYcrWd3ZUOgwxqyt8trOd3U1mVQW29GxURyy9zssGuEfn7LUSobmqxtwc+KCzJoaGpj80EbBW2JIcQ9sfEwFScbue+66dx00XiiI4VnQ/iqYWVJJQkxkSzIcw3o+OXzwqsRuq29g/99o4wLc1IoGuDfwPjGwnwXMZERthY0lhhCWn1jKz97bR9FeS4un5pGakIMxQUZ/PG9o7S0hd7lcHuH8urOShZNTx/wAvfTMhO5eOKYsGmEXvH+MY7UNfJ3i/I+NLDPDK+E2CgunTKWNbuqwuK15A1LDCHs52/s5+S5Vu67bvr5bcsKs6k928Jru0NvsM6WQyc5caaFJX30RupJ53Tcod4I3d6hPLy2jOmZiSwuSA90OCNS8YwMDtaeY3/NyB4FbYkhRB2vb+TX6w+wdM44LhiffH775flppCfG8tyWI32cHZxWllQSExnBoumD+1AMl0bolSWV7K85y71X2dVCoCx2XnsjvTrJEkOI+uGre1GFb1wzrcv2qMgIbp6bzdo9NVSfbgpQdIOnqqwqrWRhvovRsVGDOtezEbouRBuhVZWfrS1jcloC112Q1f8JZliMSxnFjKykET8K2hJDCNpbdZrntlTwN5dOJCf1w9MwLyvMpr1DeXFr6IxpKD3WwNFTjT3OjTQQnY3QL4RoI/Rru6vZdbyBL12ZR2Qvo72NfxTPyGDLoZMh+yXDFywxhKDv/3U3CbFR3NvLxGpT0kYzd0IKz26pCJlGtJUllURGyPkJzQYrlBuhVZWfvlZG9phRLJ0zLtDhjHjFBel0KKwNwXY6X7HEEGLeKa9lze5qvnjlFMb0sSD8bYU5lFWfYduRU36MbuhWllYyPzfVq0XuQ7UResP+WrYdOcUXrphCdD+D+szwu2BcMumJsazZPXKrk+xVGEJUle/9dTeZSXF8dkFun8d+dHYWcdERPLsl+KtWyqpPU1Z9ZkCD2vrysdlZJIVYI3R7h/KDVXtIT4zl1ouzAx2OASIihMUFGby59wTNbe2BDicgLDGEkJd3VPL+kVN8/eqp/fbzT4yL5voLsvjTtmM0tgT3i3tVqfub2TUzvEsMcdGR3BxijdBPbDzE+0dO8S/XFwx47IYZfsUF6ZxpbuOd8tC6+vQVSwwhorW9g4dW7WZqxmhuGeA3y2WFOZxubmNVaeUwR+edlSWVXDQhhczkOK8fK5QaoY/XN/KDlbtZmO+ytoUgsyDPRVx0xIjtnWSJIUQ8uekwB2vPcd910wfca2V+bio5qaN4NojHNFScPMeOo/V9TrE9GKHUCP3tl0ppV+WBG2fZuIUgExcdSVFeGqt3VQf962g4WGIIAWea2/jx6n3Mz01l0bSBD/6KiBBunZvDW2W1HKk7N4wRDl1nNdJgRzv3JRQaoVeWVPLKziq+WjyVCWM/3OXYBF5xQTpHTzWyu/J0oEPxO58kBhG5VkT2iEiZiNzXw/6vi8hOEdkuImtEZKLHvnYR2eb8rPBFPOHm0TfLqT3bwjevLxj0N8tbLh6PCEE7ydyqkkqmZyYyyYcL3Qd7I3RDUyvfXlFCQVYSdxf13YnABM5VzijokVid5HViEJFI4GHgOmAGsFxEZnQ77D2gUFVnA88BP/DY16iqc5yfG7yNJ9xUNzTx2LpyPjorizk5g1/JK3tMPAumuHhuSwUdHcF1SVxzupl3D9X59GoBgr8R+qGVe6g+3cyDN8+y7qlBLD0pjgtzUli9a+SNZ/DFq3IeUKaq5araAjwFLPU8QFXXqmpnXcZGwPrlDdCP1uyjpa2Df1wyrf+De7GsMJuKk41sPFDrw8i8t3pXFap43U21J8HaCL3l0EmeeOcQd146iQuHkOiNfxVPT2fbkVMhNb2ML/giMYwHPFs3K5xtvbkb+KvH/TgR2SwiG0XkRh/EEzb215zh6XePcMf8CV5VtSyZmUliXFTQrdOwsqSSiWPjmZ6Z6PPHDsZG6Ja2Dv7lhR1kJsXxDS8SvfGfxc5I/JE2CtoXiaGnSu8e34ki8imgEHjIY/MEVS0E7gB+JCJTejn3HieBbK6pGRkLdv9g5W7ioiL4yuJ8rx4nLjqSj184jr+WHKehqdVH0XmnvrGVDftPcO3MzGHrkXNHkDVC/3JdOXuqTvPvSy8Y9ESBJjAKshIZnzJqxFUn+SIxVAA5HvezgWPdDxKRYuBbwA2q2ty5XVWPOb/LgdeBi3oqRFUfVdVCVS1MS0vzQdjBbcuhOlaVVvH5K6bgGh3r9ePdVphDU2sHf9l+3AfReW/t7mpa23XIk+YNxEeDqBH6wImz/HjNPq6flUnxjKHNB2X8T0RYXJDOun01NLUG90BRX/JFYngXyBeRXBGJAW4HuvQuEpGLgF/gTgrVHtvHiEisc9sFLAB2+iCmkKaq/OfLu0lLjOVzC33Ta+XC7GTy00fzzObgGNOwsqSSjKRY5mQPXz17sDRCqyrfenEHsZERfPvjMwMWhxmaxQUZNLV2sGH/iUCH4jdeJwZVbQPuBVYBu4BnVLVURL4rIp29jB4CRgPPduuWWgBsFpH3gbXAg6o64hPDqzur2HzoJF8tzic+xjdVDiLCssJs3jt8irLqwPbLbmxp5/W91SyZmUnEME8xHQyN0M9vPcqG/bX883XTyUjyfnS38a+PTE4lISZyRFUn+aSvnKq+rKpTVXWKqj7gbLtfVVc4t4tVNaN7t1RV3aCqs1T1Quf3r3wRTyhra+/g+yt3MzktgU8U5vR/wiDcdFE2kRES8In13thbQ1Nrh89GO/cl0I3QtWea+Y+/7OTiiWO4Y94Ev5dvvBcbFcnlU9NG1FrQ1ok6yDyzuYL9NWf5pyXTifJxH/e0xFgWTUvnha1HaWvv8OljD8aq0kpS4qOZl5vql/IC2Qj9wF92cba5jf+8edawXx2Z4bO4IIOqhmZKjjYEOhS/GFGJYdfxBkqP1Qc6jF6da2njh6v3cvHEMSyZOTwNlMsKs6k53cwbewPTs6ulrYM1u6ooLsjweeLrTWcj9B/e8W8j9Lp9Nbzw3lG+cMUUpmb4vkuu8Z9F09KIkJGzFvSISQyqyv/7YwnLfv42r+4Mzn/ur9YdoOZ0M9+8bvqwdeG8ano6YxNiAjamYWN5LQ1NbX6pRurU2Qi9ssR/jdCNLe1868UScl0JfLmXlfZM6Bg7Opa5E8ZYYgg3IsIjn5xLfvpo7vndZh59c39Q1RfWnmnmF2+Wc82MDAonDV8VS3RkBDddNJ41u6sC0lNnZWkl8TGRFOW7/Fquvxuhf7xmH4frzvG9m2bZOgthYnFBBqXHGjhe3xjoUIbdiEkM4J775OnPX8r1F2TxvZd3c9/zO2hpC1xdu6efvlZGY2s7/3Tt9GEva1lhDq3tyh/fOzrsZXlq71BeKa1i0fR0v39Y+rMRetfxBn65rpxlF2dz6ZSxw1qW8Z+rZ3ROqhf+vZNGVGIAd7XCT5dfxFeuyuPpzUf49K/f4dS5wE60dvDEWZ7YeIjbCnPISx897OVNy0xkdnYyz2w+4terpq2HT3LiTLNfq5E8+aMRur1Due+FHaSMiuZfri8YtnKM/01JG83EsfEjojppxCUGcK9T8PVrpvGjT8xh66FT3PTIBsprzgQsnode2UN0ZARfK/Zu6ovBWFaYw+7K05Qe818vi5UllcRERrBo+sDXlPAlfzRC/+7tg7x/5BT3f3wGYxJihq0c438iwuLpGWzYX8u5lrZAhzOsRmRi6HTjReP5w9/Op6GxlZse2RCQkY3vHznFX7Yf53MLc0n34+CnG2aPIyYqgmf9NBJaVVlZUsnCfFfA5gka7kboY6caeWjVHi6fmsYNF9pSneGoeEY6LW0drNsX3qOgR3RiACiclMofv7yA9MRYPv2rTTzlx3l1VJX//OsuxibEcM/lk/1WLkByfDRLZmbyx23H/DIHTOmxBo6eahzWuZEG4o75w9MIrarcf36pzgtsqc4wdcmkVBLjolgdpD0bfWXEJwaAnNR4nv/SZSzIc3HfCzt44C87affDojav76lhY3kdX1mcT2Jc9LCX192yi7Opb2z1S53pypJKIiOE4oLATiA3NSORwmFohF5VWsnqXVV8rXgqOam2VGe4io6M4Mpp6azdUx10C1/5kiUGR1JcNL+6s5C7LpvEL9cd4PO/28zZ5uGrR2zvUB78624mjo1neYCmSliQ52JccpxfxjSsKq1k3qRUUoOg3t3Xa0I3NLVy/0ulzLClOkeE4oJ0TpxpYVvFqUCHMmwsMXiIiozgOzfM5N+XzmTtnhpu/fnbHD01PH2WX9hawZ6q0/zjkmnERAXm3xAZIdxycTbr9tUMa9/ssuoz7Ks+MywrtQ2FrxuhH1q5hxNnmvnPm2f5bTS3CZwrp6YTGSFhXZ1kr+Ie/M2lk/j1XZdQUXeOpT97i21HfPvNoKm1nf95dS8XZifz0VlZPn3swbr14mw6FF7YOnxjGlaVVgJwzTBN8zFYvmyE3nKozr1U52W2VOdIkRwfzSWTxoT1eAZLDL24YmoaL3zpMkbFRPCJX7zNn7d/aO2hIfvNWwc5Xt/EfdcVBLyRcuLYBOblpvLsMI5pWFVayZycFLKSRw3L4w9FZyP0817MNNvS1sE3X9hBVlIc/3CNLdU5khQXZLCn6jRH6s71f3AIssTQh/yMRP74pQXMzk7m3j+8x0/W7PP6w/Pk2RYeeb2Mq6anB82o2NsKczhYe47Nh076/LGPnmpke0V90FQjdepshH7Si0boR9/cz96qM3zXluoccTo7UYTrYDdLDP0YOzqWJz43n5vnjud/Xt3LV5/e5lX3zofXlnG2uY1/9sPUFwN1/axMEmIieeZd349pWFXirkZaEqDRzn1ZPm8C5SeG1gh94MRZfvJamS3VOUJNciUwJS0hbKuTLDEMQGxUJP+97EL+cck0Xtp2jDt+uZETZ5r7P7GbI3Xn+L+3D3HL3GymZQbPNMzxMVF8dHYWf9lx3Oc9sVaWVjI9M5FcV4JPH9cXhtoIrar8yws7iI2K4Du2VOeIVTwjg3cO1NLQ1BroUHzOEsMAiQhfXpTHI5+cy87jDSz92VvsqRzcEpn/8+peRODr10wdpiiH7rbCHM61tPPyjuM+e8ya0828e7AuKK8WYOiN0M9tqeDt8lruu266X0erm+BSXJBBa7vyZoDWNhlOlhgG6fpZWTzz+Utpbe/glv/dwNo9A7uULDlaz4vvHeUzC3KDqhG208UTxzDZleDTZT9X76pClaBrX/A02Ebo2jPNPPDyLgonjmH5JbZU50g2d8IYkkdF88YeSww9EpFrRWSPiJSJyH097I8Vkaed/e+IyCSPfd90tu8RkSW+iGe4zc5O4aV7FzAhNZ67f/suv3nrQL8NmN9fuZuU+Gi+eOUUP0U5OCLuMQ2bDtRx8MRZnzzmqtJKJqTGMz2Iqs26G2wj9H/YUp3GERkhXDZlLG+VnQiqtV18wevEICKRwMPAdcAMYLmIzOh22N3ASVXNA34IfN85dwZwOzATuBZ4xHm8oJeVPIpnv3Apiwsy+Lc/7eT/vVRCay/rKK/bV8O6fSe4d1EeyaP8P/XFQN0yN5sIcVeVeKuhqZW3yk5w7QWZAe+S25/ORuiN5X03Qr+5t4YX3zvKF6+YQr4t1WmAonwXx+qbKPfRl6lg4YsrhnlAmaqWq2oL8BSwtNsxS4HHndvPAYvF/WmxFHhKVZtV9QBQ5jxeSEiIjeIXn7qYz18xmSc2Huazv32X+sauDVEdztQX2WNG8TeXTgxQpAOTmRzH5VPTeH5rhddzRa3dXU1ruwZt+4KnzkboJ/uYQLGxpZ1v/XEHk10JfMmW6jSOhXlpAKwPs9lWfZEYxgOe/RwrnG09HqOqbUA9MHaA5wIgIveIyGYR2VxTEzx1ehERwjevK+AHt8zm7f213PzIWxyq/eDbw4r3j1F6rIFvXDON2KjgvxhadnEOx+ubWF/m3Qt9ZUkl6YmxXBQCo4EH0gj94zX7OFLXyPdutqU6zQcmjI0nJ3WU1++XYOOLxNBTPUH3r5u9HTOQc90bVR9V1UJVLUxLSxtkiMPvtkty+N3d86k928KND7/FpgN1NLe189CqPcwclxQy8/MXz0gnJT7aq3UaGlvaeX1PDUtmZoZMPXxfjdA7j7mX6rytMJuPTA6OQYkmeBTlpbFxfy1tvVQlhyJfJIYKIMfjfjbQff6I88eISBSQDNQN8NyQcemUsfzxSwsYkxDDJx/byJd//x5HTzVy33XTQ+YDMjYqkqUXjuOVnVXUnxta/+w399XQ2Noe1L2RuuutEbq9Q/nmC9ttqU7Tq4X5Lk43t/F+GM226ovE8C6QLyK5IhKDuzF5RbdjVgB3OrdvBV5T97tvBXC702spF8gHNvkgpoCZ5EoCO0q1AAAZEElEQVTgxS8uYF5uKqt3VbEw38XC/OC7wunLssIcWto6WPH+0CbWW1VSSUp8NPNyU30c2fC6Y/6HG6F/9/ZB3q+o5/6PzyAlPvBThpvgc+nksYjA+n21gQ7FZ7xODE6bwb3AKmAX8IyqlorId0XkBuewXwFjRaQM+Dpwn3NuKfAMsBNYCXxZVYd/ObFhlhwfzW8/M49/XzqT798yO9DhDNoF45MpyErimSGs09DS1sHqXVUUF2QQHWJTUF8/K4vkUdHnG6FtqU4zEGMSYpg1Ppn1ZcHT9uktn8z8paovAy9323a/x+0mYFkv5z4APOCLOIJJdGQEf3PppECHMWTLLs7mu3/eye7KBqZnJg34vI3ltTQ0tXFtCPRG6s7dCD2e3288TN3ZFu5/qcSW6jQDsiDPxS/fLOdMc1tYTKgYWl/pjN/ceNF4oiNl0Ku7rSytJD4mkqJ81zBFNryWz3M3Qn/lyfdYvauar19tS3Wa/i3Mc9HWobxTHh7VSZYYTI9SE2IoLsjgj+8dpaVtYL0t2juUV0qrWDQtPWS7dHY2Qq8vO8GMrCQ+u8CW6jT9mztxDHHREawLk/EMlhhMr5YVZlN7toXXdg9sPqj3Dp/kxJlmloRQb6SefGZBLjFRETx4iy3VaQYmLjqSSyal8laYjGewV73p1eX5aaQnxvLcloGNaVhZUklMZASLpoVWL6zuPjo7i/fvv4bZ2cE/OM8Ej4X5LvZVn6GyvinQoXjNEoPpVVRkBDfPzWbtnhqqT/f9YldVVpZWUpTvIjEueOeDGqhRMaFZFWYCp6hzeowwuGqwxGD6tKwwm/YO5cWtfY9pKD3WQMXJxpDsjWSML0zPTGRsQkxYVCdZYjB9mpI2mrkTUnh2S0WfUwuvKq0kQrBlLs2IFREhLMhzsT4MpuG2xGD6tawwh7LqM2w70vuQ/5UllczPHUtqgo0ONiNXUb6LmtPN7Kka3OqOwcYSg+nXx2ZnERcd0evqbmXVZ9hXfSak5kYyZjgU5bnH74T6NNyWGEy/EuOiuf6CLP607RiNLR+esWRVaSUA18y0aiQzso1LGcXktISQb4C2xGAG5NbCbE43t51PAp5eKa1kTk5KUK5lbYy/FeW5eKe8bsADQ4ORJQYzIB/JHUtO6iie7Tam4eipRt6vqA+JldqM8YeiPBeNre1sPXwy0KEMmSUGMyAREcKtc3N4q6yWI3Xnzm9/xbmCWGLVSMYA8JEpY4mMkJBuZ7DEYAbslovHIwLPb/2gEXplSSXTMhKZnDY6gJEZEzyS4qK5MDs5pNsZLDGYAcseE89lU8by3JYKOjqUE2eaefdgXcjPjWSMrxXlp7G94tSQV0EMNEsMZlBuK8yh4mQjGw/UsnpnFR2KjXY2ppuF+S46FN4uD82rBksMZlCWzMwkMS6KZzdXsLK0kgmp8RRkJQY6LGOCypycFBJiIkO2Oin0lxoyfhUXHcnHLxzHC1sraO9QPrMg11Y3M6ab6MgIPjJ5bMg2QHt1xSAiqSLyqojsc36P6eGYOSLytoiUish2EfmEx77fisgBEdnm/MzxJh7jH7cV5tDU2kFru1o3VWN6sSDPxcHac1168YUKb6uS7gPWqGo+sMa539054NOqOhO4FviRiHhOdP+PqjrH+dnmZTzGDy7MTiY/fTTpibFclGNrFhjTk4XO8rahONuqt1VJS4ErnduPA68D/+x5gKru9bh9TESqgTSg9xnZTFATEX56x0U0tXYQEWHVSMb0JC99NBlJsawrO8Ht8yYEOpxB8faKIUNVjwM4v9P7OlhE5gExwH6PzQ84VUw/FJHYPs69R0Q2i8jmmpoaL8M23pqemcQcu1owplci7mm4N5SdoKMjtKbh7jcxiMhqESnp4WfpYAoSkSzgd8BnVLVzEpFvAtOBS4BUul1teFLVR1W1UFUL09JCe+lIY8zIsDDfxclzrew83hDoUAal36okVS3ubZ+IVIlIlqoedz74e1w1XkSSgL8A/6qqGz0e+7hzs1lEfgN8Y1DRG2NMEFvgTMO9bt8JLhifHOBoBs7bqqQVwJ3O7TuBl7ofICIxwIvA/6nqs932ZTm/BbgRKPEyHmOMCRrpiXFMy0gMuQZobxPDg8DVIrIPuNq5j4gUishjzjG3AZcDd/XQLfX3IrID2AG4gP/wMh5jjAkqRfkuNh2so6n1w2uZBCuveiWpai2wuIftm4HPObefAJ7o5fyrvCnfGGOCXVG+i1+tP8C7B+tYmB8a7aM2JYYxxgyj+bmpREdKSE2PYYnBGGOGUXxMFHMnjAmp6TEsMRhjzDArynNReqyBurMtgQ5lQCwxGGPMMCsKsekxLDEYY8wwm52dQmJcVMhUJ1liMMaYYRYZIVw2ZSzry06gGvzTY1hiMMYYPyjKT+PoqUYO1gb/NNyWGIwxxg8WOtNjrN8X/JOAWmIwxhg/mDg2nvEpo0JiPIMlBmOM8QMRYWG+iw37a2lr7+j/hACyxGCMMX6yIM/F6aY2th+tD3QofbLEYIwxfrIgz4UIvBXk3VYtMRhjjJ+kJsQwc1wS64K8ncESgzHG+NGCPBfvHT7J2ea2QIfSK0sMxhjjRwvz0mhtVzYdqAt0KL2yxGCMMX5UOGkMsVERrAvidgZLDMYY40dx0ZFcMik1qCfUs8RgjDF+VpTvYk/VaaobmgIdSo+8Sgwikioir4rIPuf3mF6Oa/dY73mFx/ZcEXnHOf9pEYnxJh5jjAkFRZ3TYwTpVYO3Vwz3AWtUNR9Y49zvSaOqznF+bvDY/n3gh875J4G7vYzHGGOC3oysJFITYsI2MSwFHnduPw7cONATRUSAq4DnhnK+McaEqojOabj3Bec03N4mhgxVPQ7g/E7v5bg4EdksIhtFpPPDfyxwSlU7O/NWAON7K0hE7nEeY3NNTfDPTmiMMX0pynNRfbqZfdVnAh3Kh0T1d4CIrAYye9j1rUGUM0FVj4nIZOA1EdkBNPRwXK+pU1UfBR4FKCwsDL4Ua4wxg9C53Of6fSeYmpEY4Gi66jcxqGpxb/tEpEpEslT1uIhkAdW9PMYx53e5iLwOXAQ8D6SISJRz1ZANHBvCczDGmJCTPSaeXFcC68tO8Nmi3ECH04W3VUkrgDud23cCL3U/QETGiEisc9sFLAB2qrtibS1wa1/nG2NMuFqQN5aN5bW0Btk03N4mhgeBq0VkH3C1cx8RKRSRx5xjCoDNIvI+7kTwoKrudPb9M/B1ESnD3ebwKy/jMcaYkFGUl8a5lnbeO3wq0KF00W9VUl9UtRZY3MP2zcDnnNsbgFm9nF8OzPMmBmOMCVWXThlLhLiX+5yXmxrocM6zkc/GGBMgyaOimZ2dEnTjGSwxGGNMAC3Md/F+RT0NTa2BDuU8SwzGGBNAC/JctHcob++vDXQo51liMMaYAJo7YQzxMZFBNduqJQZjjAmgmKgI5uemsj6I1mewxGCMMQG2IM9F+YmzHD3VGOhQAEsMxhgTcAvz0wB4K0iuGiwxGGNMgE3NGE1aYizrgqSdwRKDMcYEmIhQlOdiQ9kJOjoCP0eoJQZjjAkCRXkuas+2sKuyp4mn/csSgzHGBIEFeR9Mwx1olhiMMSYIZCbHkZ8+Oiimx7DEYIwxQaIo38WmA3U0tbYHNA5LDMYYEySK8lw0t3Ww5dDJgMZhicEYY4LE/MljiYqQgFcnWWIwxpggMTo2irkTxgS8AdoSgzHGBJEFeS5KjtVz8mxLwGKwxGCMMUGkKN+FKmwI4DTcXiUGEUkVkVdFZJ/ze0wPxywSkW0eP00icqOz77cicsBj3xxv4jHGmFB3YXYyibFRrC+rCVgM3l4x3AesUdV8YI1zvwtVXauqc1R1DnAVcA54xeOQf+zcr6rbvIzHGGNCWlRkBB+ZMjagDdDeJoalwOPO7ceBG/s5/lbgr6p6zstyjTEmbC3Md3GkrpFDtWcDUr63iSFDVY8DOL/T+zn+duDJbtseEJHtIvJDEYnt7UQRuUdENovI5pqawF1iGWPMcOucHmNdgHon9ZsYRGS1iJT08LN0MAWJSBYwC1jlsfmbwHTgEiAV+OfezlfVR1W1UFUL09LSBlO0McaElMmuBMYlxwVsuc+o/g5Q1eLe9olIlYhkqepx54O/uo+Hug14UVVbPR77uHOzWUR+A3xjgHEbY0zYEhGK8l2sKq2ivUOJjBC/lu9tVdIK4E7n9p3AS30cu5xu1UhOMkFEBHf7RImX8RhjTFhYkOeivrGVkqP1fi/b28TwIHC1iOwDrnbuIyKFIvJY50EiMgnIAd7odv7vRWQHsANwAf/hZTzGGBMWzk/DHYDqpH6rkvqiqrXA4h62bwY+53H/IDC+h+Ou8qZ8Y4wJV67RsczISmLdvhq+vCjPr2XbyGdjjAlSRfkuth46xbmWNr+Wa4nBGGOCVFGei5b2DjYdqPNruZYYjDEmSF0yKZWYyAi/z7ZqicEYY4LUqJhICieN8XsDtCUGY4wJYkX5LnZXnqbmdLPfyrTEYIwxQazI6bbqz1HQlhiMMSaIzRyXTEp8tF+rkywxGGNMEIuMEBZMcbF+3wlU1S9lWmIwxpggtyDPRWVDE/tr/DMNtyUGY4wJcgvznekx9vlnyQFLDMYYE+RyUuOZODbeb+0MlhiMMSYELMhzsbG8jtb2jmEvyxKDMcaEgIV5Ls62tLGn8vSwl+XV7KrGGGP8Y9H0dLb869WkJsQMe1mWGIwxJgTERUcSFx3pl7KsKskYY0wXlhiMMcZ0YYnBGGNMF14lBhFZJiKlItIhIoV9HHetiOwRkTIRuc9je66IvCMi+0TkaREZ/lYVY4wxffL2iqEEuBl4s7cDRCQSeBi4DpgBLBeRGc7u7wM/VNV84CRwt5fxGGOM8ZJXiUFVd6nqnn4OmweUqWq5qrYATwFLRUSAq4DnnOMeB270Jh5jjDHe80cbw3jgiMf9CmfbWOCUqrZ1294jEblHRDaLyOaaGv/MF2KMMSNRv+MYRGQ1kNnDrm+p6ksDKEN62KZ9bO+Rqj4KPOrEVCMihwZQdk8mAIeHeO5QJAP1YVhWuJcXzs/N3+WF83Pzd3neljVxIAf1mxhUtdiLIMB9JZDjcT8bOAacAFJEJMq5aujc3i9VTRtqMCJSo6q9NpT7mog8qqr3hFtZ4V5eOD83f5cXzs/N3+X5qyx/VCW9C+Q7PZBigNuBFepecWItcKtz3J3AQK5AvHXKD2V4+lOYlhXu5YXzc/N3eeH83Pxdnl/KEm9WBBKRm4CfAmm4P3C3qeoSERkHPKaq1zvHXQ/8CIgEfq2qDzjbJ+NujE4F3gM+parDuuK1iGz25xWDMcaEGq8SQygSkXuc9gpjjDE9GHGJwRhjTN9sSgxjjDFdWGLwkoi0i8g2j59JfRx7pYj82YuyVER+53E/yum6O+THHGC5NzllTx+mxw/I83LKOjPcZQy2TBF5va8pZgZYxrD+z3oo71vO9DjbnffB/GEuL1tEXnKm09kvIj/ua0odEfmqiMQPoRwVkf/2uP8NEfnOEMMeSHmdnyelIvK+iHxdRPz+OR22icGPb/hGVZ3j8XNwGMs6C1wgIqOc+1cDRwfzACIylDU4lgPrcfcoG0xZA5083uvnZT5kSP+zoRCRS4GPAXNVdTZQTNdBrb4uT4AXgD860+lMBUYDD/Rx2leBQScGoBm4WURcQzh3KDo/T2bifh9cD3zbT2WfF7aJIZBEJFJEHhKRd51vUJ/32J0kIi+KyE4R+fkQvg38Ffioc3s58KRHufNEZIOIvOf8nuZsv0tEnhWRPwGvDPK5jAYW4J7H6nZn25Ui8mZPz0NEzojId0XkHeDSYX5e60Rkjsdxb4nI7ME8P4/n82eP+z8Tkbuc2wdF5N9EZKuI7PDVN/C+yvTBY/f2P+vtOV4vIrtFZL2I/GQIV2pZwInOHoWqekJVj4nIxSLyhohsEZFVIpLllPe6iPzI+V+WiMi8QZZ3FdCkqr9xymsHvgZ8VkQSROS/nP/VdhH5OxH5CjAOWCsiawdZVhvugbVf675DRCaKyBqnnDUiMkFEkp3XTOf7IV5EjohI9CDLRVWrgXuAe8Wt188VEfkn5zm/LyIPDras7sI6MYjIaOcf1vmmXupsnyQiu0Tkl84l2yse31YHa5R8UI30orPtbqBeVS8BLgH+VkRynX3zgH8AZgFTcE9COBhPAbeLSBwwG3jHY99u4HJVvQi4H/iex75LgTtV9apBlncjsFJV9wJ1IjK3n+eRAJSo6nxVXT/Mz+sx4C4AEZkKxKrq9kE+v4E4oapzgf8FvjEMj+9rvf3PPsT5e/8CuE5Vi3B3PR+sV4AcEdkrIo+IyBXOB+FPgVtV9WLg13T9Rp+gqpcBX3L2DcZMYIvnBlVtwD2jweeAXOAi5+rl96r6E9yDZxep6qIhPL+HgU+KSHK37T8D/q+zHOAnqloPvA9c4RzzcWCVqrYOoVxUtRz353Q6vXyuiMh1uP/n81X1QuAHQynLU1gnBqAJuMl5Uy8C/ltEOqfiyAcedi7ZTgG3DLEMz6qkm5xt1wCfFpFtuD/gxjrlAWxyJhRsx/2tuGgwhTkffJNwf6t+udvuZOBZESkBfoj7DdTpVVWtG0xZjuW4P7Rxfi93bvf2PNqB5wdbyBCf17PAx5wPoc8Cvx1suQP0gvN7ixNjsOvtf9aT6UC5qh5w7j/Zx7E9UtUzwMW4v93WAE8DnwcuAF513gf/int2g05POue+ifsqOmUQRQo9T58jwOXAzzvnYBvia74LJ+n8H/CVbrsuBf7g3P4dH7wHngY+4dy+3bnvjc7PrN4+V4qB36jqOSder59zuK/5LMD3RORyoAP3JH0Zzr4DqrrNue3rN7wAf6eqq7psFLmSD7+gh9JfeAXwX8CVuF8cnf4dWKuqN4m7Efx1j31nB1uIiIzFfdl+gYgo7gGKivuDu7fn0eQki6EY1PNS1XMi8iqwFLgNGGqDbRtdvyTFddvfOeiyHd+9Z/orc0j6+J+t6KW8nuYsGzTnf/468LqI7AC+DJSqam/Vid68D0rp9kVORJJwT71TPsjHGqgfAVuB3/RxTGe5K4D/FJFU3AnztaEWKu5BwO1ANb1/rlyLj59zuF8xfBL3pfHFqjoHqOKDN4TnCGtfvuEBVgFf7KxXFJGpIpLg7JvnXP5F4P5WMZjqlk6/Br6rqju6bU/mg0bbu4bwuN3divtSeaKqTlLVHOAA7m9Gvnge3Q3leT0G/AR414tvSoeAGSIS61QXLB7i4wRDmb39z+ilvN3AZPmgN90nGCQRmSYi+R6b5gC7gDRxN0wjItEi4nkF+wlnexHu6pHBTAy3BogXkU87jxEJ/DfuK8ZXgC+I08nC+XAGOA0kDva5dXJeW8/Qdc2YDXzQuP9JnPeAcwW1Cfgx8OehflESkTTg58DPnCmEevtceQV3+0q8sz21t8ccqHBPDMlAtaq2isgiBjizoA88BuwEtjrVH7/gg8TzNvAg7kWODgAv9vgIfVDVClX9cQ+7foD7m8pbuL8pems5H47veeAOfPA8uhvK81LVLUADfX+T65Hz4dGsqkdwv+m3464rfm+wjxVEZfb1P/tQearaiLuef6WIrMf95Wmws3eOBh4Xd0eE7bgX5Lofd5L6voi8D2wDLvM456SIbMD9wTeoBbqcD8mbgGUisg/Yi7va+F9wv/cOA9udcu9wTnsU+OsQGp89/Tfg2TvpK8BnnOf8N8Dfe+x7GvgUg69G6myzLAVW4/7Q/zdnX4+fK6q6EvdVymanmsnrdrCwHPnsvPmqgGm4J52Kxv3CXIB7JTlwZ/ILnOO/AYxW1e/4P9rQ41SJfUNVPxYEsYzDXYUxXVU7BnnuhcAvVXWwvWKGLBBl9kdERqvqGaf97WFgn6r+cBjLex3362fzcJVhvBOubQwzgf2qeoLeu0xe0HlDVf/LL1EZn3KqEh4Avj6EpPAF3N/4vjocsQVLmQP0tyJyJxCD+0riFwGOxwRY2F0xeL75VHVQffaNMcaEYWIwxhjjnXBvfDbGGDNIIZ8YRCRHRNY6I5lLReTvne2pIvKquCfZelVExjjbRdzD/svEPax8rsdjrRSRU+KHyduMMSZYhXxiwD1Q6B9UtQD4CPBlEZkB3AescSbZWuPcB3evpHzn5x7c0xx0egh3tzNjjBmxQj4xqOpxVd3q3D6Ne2DNeNyjYR93Dnsc91wiONv/T902AiniTO6lqmtwD4QxxpgRK+QTgydn9OZFuOcRyVDV4+BOHrgnoQJ30vCcErjC2WaMMYYwSgzinmr4edzdVBv6OrSHbdY1yxhjHGGRGJy5Q57HPcVu50yYVfLB/O9ZuCehAvcVQo7H6dm4p+Q1xhhDGCQGZxj/r4Bdqvo/HrtWAHc6t+8EXvLY/mmnd9JHcE/gddxvARtjTJAL+QFuzuyM64AduKfWBvdkWu/gnjRsAu5JtZapap2TSH4GXAucAz7TOWeLiKzDPT/9aKAWuLv7FLfGGBPuQj4xGGOM8a2Qr0oyxhjjW5YYjDHGdGGJwRhjTBeWGIwxxnRhicEYY0wXlhiMMcZ0YYnBGGNMF/8fpr/9uITRgIUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_series_total.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of making a range of dates by hand, we can have pandas do it for us using the *date_range(...)* function, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('1/1/2000', periods=120, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-30',\n",
       "               '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
       "               '2000-09-30', '2000-10-31',\n",
       "               ...\n",
       "               '2009-03-31', '2009-04-30', '2009-05-31', '2009-06-30',\n",
       "               '2009-07-31', '2009-08-31', '2009-09-30', '2009-10-31',\n",
       "               '2009-11-30', '2009-12-31'],\n",
       "              dtype='datetime64[ns]', length=120, freq='M')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first date is the starting date; next, *periods* is how many dates to create. Finally, the *freq* is a code for the frequency to create the dates at. 'M' or 'm' indicates monthly; 'D' would be daily, 'min' minute-ly, and more. You can check out the  full pandas documentation for more complicated codes (e.g. quarters, business days, etc): http://pd.pydata.org/pandas-docs/stable/timeseries.html\n",
    "\n",
    "Notice that by default, pandas puts the dates for a monthly sequence at the *end* of each month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two new random walks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = pd.Series([random.normalvariate(0,1) for x in range(120)], index=dates)\n",
    "ts2 = pd.Series([random.normalvariate(0,1) for x in range(120)], index=dates)\n",
    "\n",
    "ts1 = ts1.cumsum()\n",
    "ts2 = ts2.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the first or last few entries in a series using the *head()* or *tail()* functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    1.426060\n",
       "2000-02-29    0.445800\n",
       "2000-03-31   -0.342196\n",
       "2000-04-30    0.950249\n",
       "2000-05-31   -0.300202\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.head() # First 5 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009-08-31    20.051139\n",
       "2009-09-30    18.664021\n",
       "2009-10-31    19.022552\n",
       "2009-11-30    20.176071\n",
       "2009-12-31    19.832120\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts2.tail() # Last 5 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas series have a built-in *corr(...)* function for finding the correlation between two series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4286924712619823\n",
      "-0.2300020834780193\n"
     ]
    }
   ],
   "source": [
    "print(ts1.corr(ts2)) # Defaults to Pearson correlation\n",
    "print(ts1.corr(ts2, method='spearman')) # Spearman's rank correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find a series's autocorrelation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215595122080714"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.autocorr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes\n",
    "\n",
    "If you've worked in R, you're already familiar with the general concept of dataframes. You probably know the same concept by different names in other languages and tools too -- it's just data organized into a table, with columns of specific variables and rows of observations. \n",
    "\n",
    "Technically, in Pandas, a DataFrame is a composed of Series with a shared index; each Series is a column, and each index value is a row.\n",
    "\n",
    "We can create a DataFrame from series by creating a dictionary associating each series with a column name, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Column1\": ts1, \"Column2\": ts2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>1.426060</td>\n",
       "      <td>-0.308263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.445800</td>\n",
       "      <td>-0.489707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>-0.342196</td>\n",
       "      <td>-2.600092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>0.950249</td>\n",
       "      <td>-3.708544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>-0.300202</td>\n",
       "      <td>-4.339654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-30</th>\n",
       "      <td>0.331948</td>\n",
       "      <td>-4.898070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-07-31</th>\n",
       "      <td>-1.415908</td>\n",
       "      <td>-4.210694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-08-31</th>\n",
       "      <td>-2.390147</td>\n",
       "      <td>-3.127724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-30</th>\n",
       "      <td>-4.362715</td>\n",
       "      <td>-2.458261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-10-31</th>\n",
       "      <td>-5.064677</td>\n",
       "      <td>-1.399266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-11-30</th>\n",
       "      <td>-4.503066</td>\n",
       "      <td>0.478208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-12-31</th>\n",
       "      <td>-4.284463</td>\n",
       "      <td>0.755965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-31</th>\n",
       "      <td>-5.101651</td>\n",
       "      <td>1.826302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-28</th>\n",
       "      <td>-8.539464</td>\n",
       "      <td>2.836494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-03-31</th>\n",
       "      <td>-9.078742</td>\n",
       "      <td>2.321123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-04-30</th>\n",
       "      <td>-9.018096</td>\n",
       "      <td>1.614667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-31</th>\n",
       "      <td>-9.067854</td>\n",
       "      <td>3.238385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-06-30</th>\n",
       "      <td>-7.464189</td>\n",
       "      <td>3.956110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-07-31</th>\n",
       "      <td>-6.814123</td>\n",
       "      <td>5.060129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-08-31</th>\n",
       "      <td>-7.817239</td>\n",
       "      <td>6.096953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-09-30</th>\n",
       "      <td>-6.184664</td>\n",
       "      <td>7.234660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-31</th>\n",
       "      <td>-6.668287</td>\n",
       "      <td>8.275825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-30</th>\n",
       "      <td>-5.960994</td>\n",
       "      <td>8.791999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-12-31</th>\n",
       "      <td>-6.640428</td>\n",
       "      <td>8.712506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-31</th>\n",
       "      <td>-5.976498</td>\n",
       "      <td>8.415884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-02-28</th>\n",
       "      <td>-6.198684</td>\n",
       "      <td>8.482484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-03-31</th>\n",
       "      <td>-5.339234</td>\n",
       "      <td>8.301842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-04-30</th>\n",
       "      <td>-5.634192</td>\n",
       "      <td>9.300795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-31</th>\n",
       "      <td>-5.495046</td>\n",
       "      <td>10.513218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>-6.884487</td>\n",
       "      <td>9.738778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-31</th>\n",
       "      <td>-13.408436</td>\n",
       "      <td>13.126702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-31</th>\n",
       "      <td>-11.388232</td>\n",
       "      <td>14.324405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-30</th>\n",
       "      <td>-10.545781</td>\n",
       "      <td>15.449197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-10-31</th>\n",
       "      <td>-8.989786</td>\n",
       "      <td>15.217550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-11-30</th>\n",
       "      <td>-8.961304</td>\n",
       "      <td>16.592644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>-10.538120</td>\n",
       "      <td>18.298195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-31</th>\n",
       "      <td>-8.364608</td>\n",
       "      <td>17.885868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-02-29</th>\n",
       "      <td>-6.357063</td>\n",
       "      <td>17.718075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>-7.989310</td>\n",
       "      <td>18.498856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-30</th>\n",
       "      <td>-7.061109</td>\n",
       "      <td>18.698648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-05-31</th>\n",
       "      <td>-7.770365</td>\n",
       "      <td>19.686384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30</th>\n",
       "      <td>-5.334727</td>\n",
       "      <td>21.400749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-07-31</th>\n",
       "      <td>-5.750659</td>\n",
       "      <td>21.254499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-31</th>\n",
       "      <td>-5.678810</td>\n",
       "      <td>20.466332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-30</th>\n",
       "      <td>-6.595620</td>\n",
       "      <td>20.258703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-10-31</th>\n",
       "      <td>-6.850475</td>\n",
       "      <td>21.042530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-30</th>\n",
       "      <td>-6.568002</td>\n",
       "      <td>20.857414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>-7.637343</td>\n",
       "      <td>19.418836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-31</th>\n",
       "      <td>-6.574236</td>\n",
       "      <td>19.125144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-28</th>\n",
       "      <td>-6.713103</td>\n",
       "      <td>20.237559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-31</th>\n",
       "      <td>-6.939048</td>\n",
       "      <td>20.648699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-30</th>\n",
       "      <td>-7.657314</td>\n",
       "      <td>19.648444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-31</th>\n",
       "      <td>-6.309499</td>\n",
       "      <td>18.635568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-30</th>\n",
       "      <td>-7.578322</td>\n",
       "      <td>19.807298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-07-31</th>\n",
       "      <td>-7.945191</td>\n",
       "      <td>19.526463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-08-31</th>\n",
       "      <td>-8.687754</td>\n",
       "      <td>20.051139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>-8.836098</td>\n",
       "      <td>18.664021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-31</th>\n",
       "      <td>-9.055282</td>\n",
       "      <td>19.022552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>-9.492621</td>\n",
       "      <td>20.176071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>-10.193608</td>\n",
       "      <td>19.832120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Column1    Column2\n",
       "2000-01-31   1.426060  -0.308263\n",
       "2000-02-29   0.445800  -0.489707\n",
       "2000-03-31  -0.342196  -2.600092\n",
       "2000-04-30   0.950249  -3.708544\n",
       "2000-05-31  -0.300202  -4.339654\n",
       "2000-06-30   0.331948  -4.898070\n",
       "2000-07-31  -1.415908  -4.210694\n",
       "2000-08-31  -2.390147  -3.127724\n",
       "2000-09-30  -4.362715  -2.458261\n",
       "2000-10-31  -5.064677  -1.399266\n",
       "2000-11-30  -4.503066   0.478208\n",
       "2000-12-31  -4.284463   0.755965\n",
       "2001-01-31  -5.101651   1.826302\n",
       "2001-02-28  -8.539464   2.836494\n",
       "2001-03-31  -9.078742   2.321123\n",
       "2001-04-30  -9.018096   1.614667\n",
       "2001-05-31  -9.067854   3.238385\n",
       "2001-06-30  -7.464189   3.956110\n",
       "2001-07-31  -6.814123   5.060129\n",
       "2001-08-31  -7.817239   6.096953\n",
       "2001-09-30  -6.184664   7.234660\n",
       "2001-10-31  -6.668287   8.275825\n",
       "2001-11-30  -5.960994   8.791999\n",
       "2001-12-31  -6.640428   8.712506\n",
       "2002-01-31  -5.976498   8.415884\n",
       "2002-02-28  -6.198684   8.482484\n",
       "2002-03-31  -5.339234   8.301842\n",
       "2002-04-30  -5.634192   9.300795\n",
       "2002-05-31  -5.495046  10.513218\n",
       "2002-06-30  -6.884487   9.738778\n",
       "...               ...        ...\n",
       "2007-07-31 -13.408436  13.126702\n",
       "2007-08-31 -11.388232  14.324405\n",
       "2007-09-30 -10.545781  15.449197\n",
       "2007-10-31  -8.989786  15.217550\n",
       "2007-11-30  -8.961304  16.592644\n",
       "2007-12-31 -10.538120  18.298195\n",
       "2008-01-31  -8.364608  17.885868\n",
       "2008-02-29  -6.357063  17.718075\n",
       "2008-03-31  -7.989310  18.498856\n",
       "2008-04-30  -7.061109  18.698648\n",
       "2008-05-31  -7.770365  19.686384\n",
       "2008-06-30  -5.334727  21.400749\n",
       "2008-07-31  -5.750659  21.254499\n",
       "2008-08-31  -5.678810  20.466332\n",
       "2008-09-30  -6.595620  20.258703\n",
       "2008-10-31  -6.850475  21.042530\n",
       "2008-11-30  -6.568002  20.857414\n",
       "2008-12-31  -7.637343  19.418836\n",
       "2009-01-31  -6.574236  19.125144\n",
       "2009-02-28  -6.713103  20.237559\n",
       "2009-03-31  -6.939048  20.648699\n",
       "2009-04-30  -7.657314  19.648444\n",
       "2009-05-31  -6.309499  18.635568\n",
       "2009-06-30  -7.578322  19.807298\n",
       "2009-07-31  -7.945191  19.526463\n",
       "2009-08-31  -8.687754  20.051139\n",
       "2009-09-30  -8.836098  18.664021\n",
       "2009-10-31  -9.055282  19.022552\n",
       "2009-11-30  -9.492621  20.176071\n",
       "2009-12-31 -10.193608  19.832120\n",
       "\n",
       "[120 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the DataFrame may either display the whole thing, or else just a quick summary of the index and the columns, depending on the version of pandas you have and how it's conigured. To view the summary, use the *.info()* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 120 entries, 2000-01-31 to 2009-12-31\n",
      "Freq: M\n",
      "Data columns (total 2 columns):\n",
      "Column1    120 non-null float64\n",
      "Column2    120 non-null float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column headers are stored in the *columns* property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Column1', 'Column2'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly see the data types of each column using the *dtypes* property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column1    float64\n",
       "Column2    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the index using the *index* property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-30',\n",
       "               '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
       "               '2000-09-30', '2000-10-31',\n",
       "               ...\n",
       "               '2009-03-31', '2009-04-30', '2009-05-31', '2009-06-30',\n",
       "               '2009-07-31', '2009-08-31', '2009-09-30', '2009-10-31',\n",
       "               '2009-11-30', '2009-12-31'],\n",
       "              dtype='datetime64[ns]', length=120, freq='M')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is a datetime, just like it was for the series. Each row is associated with a date.\n",
    "\n",
    "We can quickly look at the top and bottom rows using the *head()* and *tail()* methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>1.426060</td>\n",
       "      <td>-0.308263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.445800</td>\n",
       "      <td>-0.489707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>-0.342196</td>\n",
       "      <td>-2.600092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>0.950249</td>\n",
       "      <td>-3.708544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>-0.300202</td>\n",
       "      <td>-4.339654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Column1   Column2\n",
       "2000-01-31  1.426060 -0.308263\n",
       "2000-02-29  0.445800 -0.489707\n",
       "2000-03-31 -0.342196 -2.600092\n",
       "2000-04-30  0.950249 -3.708544\n",
       "2000-05-31 -0.300202 -4.339654"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-11-30</th>\n",
       "      <td>-9.492621</td>\n",
       "      <td>20.176071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>-10.193608</td>\n",
       "      <td>19.832120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Column1    Column2\n",
       "2009-11-30  -9.492621  20.176071\n",
       "2009-12-31 -10.193608  19.832120"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2) # A number specifies how many rows to include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the *corr()* method will produce a correlation table for all the columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Column1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.428692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Column2</th>\n",
       "      <td>-0.428692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column1   Column2\n",
       "Column1  1.000000 -0.428692\n",
       "Column2 -0.428692  1.000000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting columns\n",
    "\n",
    "There are two ways to access specific columns within the DataFrame. The first is by putting the columns name (in quotation marks) in square brackets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31     1.426060\n",
       "2000-02-29     0.445800\n",
       "2000-03-31    -0.342196\n",
       "2000-04-30     0.950249\n",
       "2000-05-31    -0.300202\n",
       "2000-06-30     0.331948\n",
       "2000-07-31    -1.415908\n",
       "2000-08-31    -2.390147\n",
       "2000-09-30    -4.362715\n",
       "2000-10-31    -5.064677\n",
       "2000-11-30    -4.503066\n",
       "2000-12-31    -4.284463\n",
       "2001-01-31    -5.101651\n",
       "2001-02-28    -8.539464\n",
       "2001-03-31    -9.078742\n",
       "2001-04-30    -9.018096\n",
       "2001-05-31    -9.067854\n",
       "2001-06-30    -7.464189\n",
       "2001-07-31    -6.814123\n",
       "2001-08-31    -7.817239\n",
       "2001-09-30    -6.184664\n",
       "2001-10-31    -6.668287\n",
       "2001-11-30    -5.960994\n",
       "2001-12-31    -6.640428\n",
       "2002-01-31    -5.976498\n",
       "2002-02-28    -6.198684\n",
       "2002-03-31    -5.339234\n",
       "2002-04-30    -5.634192\n",
       "2002-05-31    -5.495046\n",
       "2002-06-30    -6.884487\n",
       "                ...    \n",
       "2007-07-31   -13.408436\n",
       "2007-08-31   -11.388232\n",
       "2007-09-30   -10.545781\n",
       "2007-10-31    -8.989786\n",
       "2007-11-30    -8.961304\n",
       "2007-12-31   -10.538120\n",
       "2008-01-31    -8.364608\n",
       "2008-02-29    -6.357063\n",
       "2008-03-31    -7.989310\n",
       "2008-04-30    -7.061109\n",
       "2008-05-31    -7.770365\n",
       "2008-06-30    -5.334727\n",
       "2008-07-31    -5.750659\n",
       "2008-08-31    -5.678810\n",
       "2008-09-30    -6.595620\n",
       "2008-10-31    -6.850475\n",
       "2008-11-30    -6.568002\n",
       "2008-12-31    -7.637343\n",
       "2009-01-31    -6.574236\n",
       "2009-02-28    -6.713103\n",
       "2009-03-31    -6.939048\n",
       "2009-04-30    -7.657314\n",
       "2009-05-31    -6.309499\n",
       "2009-06-30    -7.578322\n",
       "2009-07-31    -7.945191\n",
       "2009-08-31    -8.687754\n",
       "2009-09-30    -8.836098\n",
       "2009-10-31    -9.055282\n",
       "2009-11-30    -9.492621\n",
       "2009-12-31   -10.193608\n",
       "Freq: M, Name: Column1, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Column1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are no spaces in the column name, we can also reference it as a property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    -0.308263\n",
       "2000-02-29    -0.489707\n",
       "2000-03-31    -2.600092\n",
       "2000-04-30    -3.708544\n",
       "2000-05-31    -4.339654\n",
       "2000-06-30    -4.898070\n",
       "2000-07-31    -4.210694\n",
       "2000-08-31    -3.127724\n",
       "2000-09-30    -2.458261\n",
       "2000-10-31    -1.399266\n",
       "2000-11-30     0.478208\n",
       "2000-12-31     0.755965\n",
       "2001-01-31     1.826302\n",
       "2001-02-28     2.836494\n",
       "2001-03-31     2.321123\n",
       "2001-04-30     1.614667\n",
       "2001-05-31     3.238385\n",
       "2001-06-30     3.956110\n",
       "2001-07-31     5.060129\n",
       "2001-08-31     6.096953\n",
       "2001-09-30     7.234660\n",
       "2001-10-31     8.275825\n",
       "2001-11-30     8.791999\n",
       "2001-12-31     8.712506\n",
       "2002-01-31     8.415884\n",
       "2002-02-28     8.482484\n",
       "2002-03-31     8.301842\n",
       "2002-04-30     9.300795\n",
       "2002-05-31    10.513218\n",
       "2002-06-30     9.738778\n",
       "                ...    \n",
       "2007-07-31    13.126702\n",
       "2007-08-31    14.324405\n",
       "2007-09-30    15.449197\n",
       "2007-10-31    15.217550\n",
       "2007-11-30    16.592644\n",
       "2007-12-31    18.298195\n",
       "2008-01-31    17.885868\n",
       "2008-02-29    17.718075\n",
       "2008-03-31    18.498856\n",
       "2008-04-30    18.698648\n",
       "2008-05-31    19.686384\n",
       "2008-06-30    21.400749\n",
       "2008-07-31    21.254499\n",
       "2008-08-31    20.466332\n",
       "2008-09-30    20.258703\n",
       "2008-10-31    21.042530\n",
       "2008-11-30    20.857414\n",
       "2008-12-31    19.418836\n",
       "2009-01-31    19.125144\n",
       "2009-02-28    20.237559\n",
       "2009-03-31    20.648699\n",
       "2009-04-30    19.648444\n",
       "2009-05-31    18.635568\n",
       "2009-06-30    19.807298\n",
       "2009-07-31    19.526463\n",
       "2009-08-31    20.051139\n",
       "2009-09-30    18.664021\n",
       "2009-10-31    19.022552\n",
       "2009-11-30    20.176071\n",
       "2009-12-31    19.832120\n",
       "Freq: M, Name: Column2, Length: 120, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Column2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The square bracket notation is also how we create new columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"New Column\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>New Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>1.426060</td>\n",
       "      <td>-0.308263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>0.445800</td>\n",
       "      <td>-0.489707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>-0.342196</td>\n",
       "      <td>-2.600092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-30</th>\n",
       "      <td>0.950249</td>\n",
       "      <td>-3.708544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-31</th>\n",
       "      <td>-0.300202</td>\n",
       "      <td>-4.339654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Column1   Column2  New Column\n",
       "2000-01-31  1.426060 -0.308263           1\n",
       "2000-02-29  0.445800 -0.489707           1\n",
       "2000-03-31 -0.342196 -2.600092           1\n",
       "2000-04-30  0.950249 -3.708544           1\n",
       "2000-05-31 -0.300202 -4.339654           1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that since there's a space in the name, we can't reference it as *df.* anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with real data\n",
    "\n",
    "Playing with toy data is fine, but to really dive into pandas let's use it to replicate and expand on some of our analysis last week.\n",
    "\n",
    "We can load a CSV file into a pandas DataFrame using the *read_csv(...)* function. Let's step through and try to load last week's MovieData.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 38, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-d9440e44d3bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MovieData.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\jenkij\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jenkij\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jenkij\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\jenkij\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 38, saw 2\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(\"MovieData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a scary-looking error, but read down to the end. \"Error tokenizing data\" probably means that there's an issue splitting the data into columns. It turns out that *read_csv* assumes by default that the data is comma-delimited. We need to explicitly give it a separator ('sep') if it's something different, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"MovieData.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, no errors now! Let's see what it's loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good, up until the end. We've got the correct column names, and a correct-seeming number of values. But we know that Budget, US Gross and Worldwide Gross are all supposed to be numbers; why is it reading them in as objects (which, in cases like this, generally means 'strings', since Pandas doesn't provide an explicit string datatype the way it does for ints and floats).\n",
    "\n",
    "As you may remember from last week, missing values were actually filled with a text string denoting this. Helpfully, *read_csv* lets you specify one or more 'na_values' which it should read as indicating missing data. To figure out what we should include there, however, we can use the *unique()* method, which returns all the unique values of a Series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"US Gross\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, see it? It's the word 'Unknown', so let's give that as our N/A Value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"MovieData.csv\", sep='\\t', na_values=\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost there! US Gross is now a numeric column, but Worldwide Gross isn't. So let's check again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Worldwide Gross\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like at least one record has 'Unkno' as its value. Luckily, we can pass *na_values* a list of values, and it will treat all of them as indicators of no data.\n",
    "\n",
    "(Incidentally, to make your code more readable, you can insert line-breaks inside of parentheses, and Python will treat them as the same line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"MovieData.csv\", sep='\\t', \n",
    "                         na_values=[\"Unknown\", \"Unkno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the 'NaN' cells -- NaN stands for Not a Number. If we want, we can replace NaN values with 0s using the *fillna(...)* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(It probably isn't best analytic practice to assume that missing data is just zero, but we'll do it now anyway for demonstration purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, though, we want to be able to actually work with the dates. We can tell pandas to parse one or more columns as dates when it loads the data, using the *parse_dates* parameter. If we assign a list of column numbers to it, it will attempt to automatically parse those columns as dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"MovieData.csv\", sep='\\t', \n",
    "                         na_values=[\"Unknown\", \"Unkno\"], parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the Release_Date column has been read as a datetime object. Now, to check whether it's parsed it correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(movies[\"Release_Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(movies.Release_Date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like the built-in date parser isn't very good at figuring out which dates are in the 20th century, and which are in the 21st. Fortunately, we already solved this problem last week; we can bring in our custom parser, and tell Pandas to use that, using the *date_parser* parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_date(date_str):\n",
    "    '''\n",
    "    Turn a MM/DD/YY string into a datetime object\n",
    "    '''\n",
    "    m, d, y = date_str.split(\"/\")\n",
    "    m = int(m)\n",
    "    d = int(d)\n",
    "    y = int(y)\n",
    "    if y > 13:\n",
    "        y += 1900\n",
    "    else:\n",
    "        y += 2000\n",
    "    return dt.datetime(y, m, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"MovieData.csv\", sep='\\t', na_values=[\"Unknown\", \"Unkno\"], \n",
    "                         parse_dates=[0], date_parser=make_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're only passing the name of the function, without the usual parentheses. Conceptually, think of this as simply passing the name of our parser function, which the *read_csv(...)* function can call on its own. For each entry, pandas will automatically call the function, and put its return value in the column. (More technically, functions in Python are first-class objects, and can be passed as arguments just like any other data type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.Release_Date.max())\n",
    "print(movies.Release_Date.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There, that's better.\n",
    "\n",
    "I mentioned earlier that we can easily create columns from other columns. Now that we have data, let's look at it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Non_US_Gross\"] = movies[\"Worldwide Gross\"] - movies[\"US Gross\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each movie, the value of the \"Non_US_Gross\" will be its Worldwide Gross minus its US Gross. The underscore in the name aren't mandatory, but they let us reference the column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.Non_US_Gross.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see above, *min()* (and *max()* as well) are built-in series functions, which can be called for columns as well. However, the Non-US Gross shouldn't be negative, since the Worldwide Gross is supposed to be inclusive of US Gross. So we want to take a closer look at those rows to figure out what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting\n",
    "\n",
    "Just because we have one big dataset doesn't mean we want to work with it all at once. Often --- like right now -- we want to be able to select only a subset of the data. In pandas, we do this by putting the condition we're selecting on in square brackets. For example, if we want only movies where the Non-US Gross is negative, we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.Non_US_Gross < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like in all these cases, the Non-US Gross is negative because Worldwide Gross is zero. Remember that we replaced missing values with zeroes, which is probably where these come from. Let's double-check this by looking at the max or min values of Non-US Gross when the Worldwide Gross column is zero. As the output above hints, the results of square bracket notation can be treated just like a DataFrame -- which means we can select columns, and it will only return the column values that are within our subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies[\"Worldwide Gross\"]==0][\"Non_US_Gross\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Worldwide Gross is supposed to be inclusive of US Gross, a sensible thing to do is to just fill these values with those of their respective US Gross. To do this, we use the subset notation again, but this time with an assignment. Note that for assignments, we put the column first, then the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Worldwide Gross\"][movies[\"Worldwide Gross\"]==0] = movies[\"US Gross\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see a warning -- similar to the one I got above. It's telling you that it can't tell whether you're operating on a copy of part of the DataFrame, or a subset. Usually you can just ignore this warning, and just make sure that the data copied the way you wanted it to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[movies.Non_US_Gross < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good (though we need to update the Non_US_Gross column). Notice that even though we didn't subset the US Gross column as we assigned it, pandas automatically matched up the correct rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Non_US_Gross\"] = movies[\"Worldwide Gross\"] - movies[\"US Gross\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.Non_US_Gross.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that correction in hand, we can continue analyzing the data. For example, let's get the profit for each movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Profits\"] = movies[\"Worldwide Gross\"] - movies[\"Budget\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few standard metrics we want to compute frequently, such as min, max, mean and median. Pandas puts all these handily together with the *describe()* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.Profits.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that pandas tries to pick the way to display numbers. Here, for example, it decides to use [scientific notation](https://en.wikipedia.org/wiki/Scientific_notation), expressing numbers as multiples of exponents of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column names are just Python values like anything else, and DataFrame.columns works basically like a list. That means that we can loop over it. For example, suppose we wanted to print the number of unique values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in movies.columns:\n",
    "    print(column, len(movies[column].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "Often, what you care about aren't individual records, but summaries aggregated at some level. For example, you may want to know how many movies were released each year, or whether certain months of the year have more earthquakes than others. \n",
    "\n",
    "Pandas uses the Split-Apply-Combine paradigm; we **split** the data into groups, **apply** a certain calculation to each group separately, and **combine** the results back into a new data structure. \n",
    "\n",
    "Let's start by getting the annual mean of each numeric column: finding the average US Gross, Worldwide Gross, etc. by year.\n",
    "\n",
    "First, we need to create a new column to aggregate on -- the Release Year. Since the values of the *Release_Date* column are datetime-like objects, they have a *year* property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.Release_Date[19].year # Some arbitrary row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a new column based on another column, with an operation that isn't basic arithmetic, we use the *apply(...)* method. This method takes another function as an input, and applies it (hence the name) to each value in a column or series. The function being applied should take a single value as an input, and produce a similar output which can be assigned to the new series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_year(date):\n",
    "    return date.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Year\"] = movies.Release_Date.apply(get_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we don't even have to define an entire function; Python allows us to use the **lambda** keyword to create a simple one-line function directly inside the *apply(...)* parentheses (you may have encountered this concept as anonymous functions in other languages). \n",
    "\n",
    "We could simplify the lines above to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"Year\"] = movies.Release_Date.apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(movies.Year.min())\n",
    "print(movies.Year.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created a Year column, we need to divide the data by its different values. We go this using the DataFrame's *groupby(...)* method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = movies.groupby('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The argument we give *groupby(...)* is the name of the column to group by. The result of the method, which is assigned here to *by_year* is a special pandas object that stores a grouped dataframe. The groups themselves are stored as a dictionary, associating group labels (e.g. years, in this case) with the indices of all the rows that belong to that group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(by_year.groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year.groups[1916]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We can carry out operations on the grouped object to yield aggragated DataFrames. \n",
    "\n",
    "The simplest of the operations built-in to the grouped data object is *mean()*, which simply returns the mean of each column for each of the groups -- in this case, the mean of each column by year. The result is a new DataFrame, indexed by year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_means = by_year.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_means.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_means.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply our own functions to each group as well, by passing them to the group object's *aggregate(...)* method. For example, if we want a count of how many movies were released in each year, we could simply pass Python's built-in *len* function, to count the length of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = by_year.aggregate(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how all the columns (except the first one) in each row have the same value --  we're just counting the number of rows per group (movies per year, in this case), which won't vary from column to column. (The Release_Date column 'remembers' that it's holding a date, and converts the count number accordingly).\n",
    "\n",
    "In fact, there's no need for a whole data frame: the count of movies per year is just a series. If we only want a single series, we can select a column from the grouped object just like from a DataFrame. For the movie counts, it doesn't matter which column we pick (with the exception of the Release_Date column). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = by_year.Movie.aggregate(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, *counts* is now a series storing the count of movies released per year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging\n",
    "\n",
    "You'll frequently find yourself working with more than one dataset at a time, or needing to combine data from several sources for analysis. Fortunately, pandas makes this simple as well.\n",
    "\n",
    "For this example, suppose we're interested in how movies are affected by the state of the American economy. First, let's put together three series: the number of movies released per year, their average budget, and their average profit.\n",
    "\n",
    "The latter two come from the *annual_means* DataFrame. We can create a DataFrame by subsetting a list of columns from another DataFrame, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data = annual_means[[\"Budget\", \"Profits\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it clear that we're looking at averages now, we may want to rename the columns. We do this using the *rename* method, and passing a dictionary to the *columns* argument, associating the old names and new names for columns we want to rename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data = annual_data.rename(columns={\"Budget\": \"Mean_Budget\", \"Profits\": \"Mean_Profit\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to add the movie count. In this case, we can simply assign it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data[\"Count\"] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since *counts* and *annual_data* have overlapping index values, pandas automatically knows how to merge them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load an additional dataset to merge in.  We'll load a simple time series with annual unemployment rates. After loading the dataset above, this is a piece of cake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp = pd.read_csv(\"Unemployment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unemp.Year.min())\n",
    "print(unemp.Year.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's been loaded as a DataFrame, with two columns: Year and Unemployment. Note that Year isn't an index, just a regular column. Our goal now is to bring the *Unemployment* column into the *annual_data* frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = annual_data.merge(unemp, how='left', left_index=True, right_on=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at what happened here. The *merge(...)* method of a DataFrame is used to merge that DataFrame (known by convention as the left-hand DataFrame) with another one (the right-hand DataFrame), provided as the first argument. DataFrames are merged by finding rows that match on some criteria, and combining them. We provide the criteria in in the *left_* or *right_* *index=* or  *on=* arguments. In the example above, we're saying to merge rows where the left-hand index matches right-hand *Year* column. \n",
    "\n",
    "The *how=* argument is the type of join to use, a concept you may be familiar with from SQL. There are three types of joins:\n",
    "\n",
    "* *left-join* means keep all the rows from the left-hand dataset, and merge in any matching right-hand rows.\n",
    "* *right-join* means keep all the rows from the right-hand dataset, and merge in any matching left-hand rows.\n",
    "* *inner-join* means keep and merge only rows where there's a match between the left- and right-hand datasets.\n",
    "\n",
    "In this case, the indices on the right-hand dataset are a subset of the left-hand indices, so a right and an inner join are equivalent. Let's quickly see what those results would look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = annual_data.merge(unemp, how='right', left_index=True, right_on=\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the *merge(...)* method returns a new DataFrame, without modifying the original DataFrame. Notice also that the resulting DataFrame has a different index; whereas previously the left-hand DataFrame was indexed on Year, the merged DataFrame has a simple row-count index, with Year now an ordinary column.\n",
    "\n",
    "If we want to, we can set the *Year* column as the index, using the *set_index(...)* method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged = data_merged.set_index(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we're assigning the result of  *set_index(...)* to the *data_merged* DataFrame itself -- again, by default it returns a new DataFrame, without modifying the original one. With most methods, instead of assigning the new DataFrame to the old name, we can use the *inplace* argument, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index, and make the old index \n",
    "data_merged.reset_index(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.set_index(\"Year\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data together, we could see whether there are any annual correlations in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like unemployment doesn't correlate at all with the number of movies released, but does correlate weakly with their average budget and profit."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
